{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DlBIm4t_CGC6"],"authorship_tag":"ABX9TyNRUSLIhMtbn53qGYBtyzVG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"fYEZBK2mASK6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4JcmmuohZk4"},"outputs":[],"source":["import os, sys\n","\n","import numpy as np\n","\n","import torch\n","\n","import time"]},{"cell_type":"markdown","source":["# For loops"],"metadata":{"id":"l8pTufAMAZqL"}},{"cell_type":"code","source":["def forloopdists(feats,protos):\n","\n","  dist=np.empty((feats.shape[0],protos.shape[0]))\n","  for i in range(feats.shape[0]):\n","    for k in range(protos.shape[0]):\n","      dist[i,k]=  np.dot( feats[i,:]-protos[k,:],(feats[i,:]-protos[k,:]).transpose()) # dot product of a vector with itself is the square of the norm of that vector\n","\n","  return dist"],"metadata":{"id":"1duAj7jHhh4A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Numpy"],"metadata":{"id":"s1nrjhYDAbjo"}},{"cell_type":"code","source":["def numpydists(feats,protos):\n","  dist0 = -2 *np.matmul(feats,protos.transpose())\n","  print(dist0.shape)\n","  dist1 = np.sum( feats**2,axis=1 )#[:,np.newaxis]\n","  print(dist1.shape)\n","  dist2 = np.sum( protos**2,axis=1 )#[np.newaxis,:]\n","  print(dist2.shape)\n","\n","  dist = dist0 + dist1[:,np.newaxis] + dist2[np.newaxis,:]\n","\n","  return dist"],"metadata":{"id":"VCUQeUW7hh63"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pytorch"],"metadata":{"id":"Kssm7xFoAf9p"}},{"cell_type":"code","source":["def pytorchdists(feats, protos):\n","  \n","  print(feats.size(),protos.size())\n","\n","  print(feats.device)\n","\n","  #dist= torch.sum(torch.pow(ft.unsqueeze(1)-prot.unsqueeze(0),2.0),dim=2) #N,P,D\n","  dist= -2*torch.mm(feats,protos.t()) \n","  dist+= torch.sum(torch.pow(feats,2.0),dim=1).unsqueeze(1) \n","  dist+= torch.sum(torch.pow(protos,2.0),dim=1).unsqueeze(0) \n","\n","  return dist.cpu().numpy()"],"metadata":{"id":"bV1HABWehh9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run everything"],"metadata":{"id":"XUF01O3KAijB"}},{"cell_type":"code","source":["########\n","##\n","## if you have less than 8 gbyte, then reduce from 250k\n","##\n","###############\n","feats = np.random.normal(size=(250000,300)) #5000 instead of 250k for forloopdists\n","protos = np.random.normal(size=(500,300))\n","\n","# since = time.time()\n","# dists0=forloopdists(feats,protos)\n","# time_elapsed=float(time.time()) - float(since)\n","# print('For loops; Comp complete in {:.3f}s'.format( time_elapsed ))\n","\n","since = time.time()\n","dists1 = numpydists(feats,protos)\n","time_elapsed = float(time.time()) - float(since)\n","\n","print('Numpy; Comp complete in {:.3f}s'.format( time_elapsed ))\n","print(dists1.shape)\n","\n","device = torch.device('cpu')\n","feats = torch.from_numpy(feats).to(device)\n","protos = torch.from_numpy(protos).to(device)\n","since = time.time()\n","dists2 = pytorchdists(feats, protos)\n","time_elapsed = float(time.time()) - float(since)\n","\n","print('PyTorch CPU; Comp complete in {:.3f}s'.format( time_elapsed ))\n","print(dists2.shape)\n","\n","device = torch.device('cuda:0')\n","feats = feats.to(device)\n","protos = protos.to(device)\n","\n","since = time.time()\n","dists3 = pytorchdists(feats, protos)\n","time_elapsed = float(time.time()) - float(since)\n","\n","print('PyTorch GPU; Comp complete in {:.3f}s'.format( time_elapsed ))\n","print(dists3.shape)\n","\n","print('df',np.max(np.abs(dists1-dists2)))\n"],"metadata":{"id":"ZVt_072VhiAX","executionInfo":{"status":"ok","timestamp":1675691957374,"user_tz":-60,"elapsed":8922,"user":{"displayName":"Ghadi Al Hajj","userId":"13429914966378993172"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"416a6884-9470-4a4f-872a-5e87641ae3a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(250000, 500)\n","(250000,)\n","(500,)\n","Numpy; Comp complete in 2.677s\n","(250000, 500)\n","torch.Size([250000, 300]) torch.Size([500, 300])\n","cpu\n","PyTorch CPU; Comp complete in 1.762s\n","(250000, 500)\n","torch.Size([250000, 300]) torch.Size([500, 300])\n","cuda:0\n","PyTorch GPU; Comp complete in 0.695s\n","(250000, 500)\n","df 3.410605131648481e-13\n"]}]},{"cell_type":"markdown","source":["## exp"],"metadata":{"id":"DlBIm4t_CGC6"}},{"cell_type":"code","source":["import numpy as np\n","import time\n","\n","feats=np.random.normal(size=(2500,300))\n","protos=np.random.normal(size=(500,300))\n","\n","since = time.time()\n","dist0 = -2 *np.matmul(feats,protos.transpose())\n","dist1 = np.sum( feats**2,axis=1 )#[:,np.newaxis]\n","dist2 = np.sum( protos**2,axis=1 )#[np.newaxis,:]\n","disti = dist0 + dist1[:,np.newaxis] + dist2[np.newaxis,:]\n","time_elapsed=float(time.time()) - float(since)\n","\n","print('Numpy1; Comp complete in {:.3f}s'.format( time_elapsed ))\n","\n","\n","print(disti.shape)\n","\n","# since = time.time()\n","# distj = np.sum(np.power(feats[:, np.newaxis] - protos[np.newaxis, :], 2), axis=2) # N,P,D\n","# time_elapsed=float(time.time()) - float(since)\n","\n","\n","print('Numpy2; Comp complete in {:.3f}s'.format( time_elapsed ))\n","\n","print(distj.shape)\n","\n","since = time.time()\n","distj = sum(np.power(a[:,np.newaxis]-b, 2) for a, b in zip(feats.T, protos.T))\n","time_elapsed=float(time.time()) - float(since)\n","\n","\n","print('native; Comp complete in {:.3f}s'.format( time_elapsed ))\n","\n","\n","\n","print('df',np.max(np.abs(disti-distj)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMlfEY4RX2h8","outputId":"7532f172-947a-4546-c368-17ae908e968b","executionInfo":{"status":"ok","timestamp":1675771621854,"user_tz":-60,"elapsed":12025,"user":{"displayName":"Ghadi Al Hajj","userId":"13429914966378993172"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Numpy1; Comp complete in 0.029s\n","(2500, 500)\n","Numpy2; Comp complete in 0.029s\n","(300, 300)\n","native; Comp complete in 11.410s\n","df 1.5916157281026244e-12\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","feats=np.random.normal(size=(2500,300))\n","protos=np.random.normal(size=(500,300))\n","\n","feats=torch.from_numpy(feats)\n","protos=torch.from_numpy(protos)\n","\n","since = time.time()\n","dist= -2*torch.mm(feats,protos.t()) \n","dist+= torch.sum(torch.pow(feats, 2.0),dim=1).unsqueeze(1) \n","dist+= torch.sum(torch.pow(protos, 2.0),dim=1).unsqueeze(0) \n","time_elapsed=float(time.time()) - float(since)\n","\n","print('Torch1; Comp complete in {:.3f}s'.format( time_elapsed ))\n","\n","\n","print(dist.shape)\n","\n","since = time.time()\n","distj = torch.sum(torch.pow(feats.unsqueeze(1)-protos.unsqueeze(0),2.0),dim=2) #N,P,D\n","time_elapsed=float(time.time()) - float(since)\n","\n","print('Torch2; Comp complete in {:.3f}s'.format( time_elapsed ))\n","\n","print(distj.shape)\n","\n","print('df', torch.max(torch.abs(dist-distj)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-b1T2e8cawaI","executionInfo":{"status":"ok","timestamp":1675665267402,"user_tz":-60,"elapsed":3928,"user":{"displayName":"Ghadi Al Hajj","userId":"13429914966378993172"}},"outputId":"a46a7550-ee6f-451b-e73b-521dafa61ff3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch1; Comp complete in 0.025s\n","torch.Size([2500, 500])\n","Torch2; Comp complete in 2.300s\n","torch.Size([2500, 500])\n","df tensor(3.4106e-13, dtype=torch.float64)\n"]}]}]}